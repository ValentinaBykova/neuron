{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdpitxhVHtN+13EJH4fTr0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinaBykova/neuron/blob/master/lab5/Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторна робота №5\n",
        "## студентки КН-31, Бикової Валентини\n",
        "## Тема: Convolutional Neural Networks and Computer Vision with TensorFlow"
      ],
      "metadata": {
        "id": "2QaBtFkN0Jav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Завдання\n",
        "#### На основі документу вирішити завдання класифікації зображень їжі для 3 класів з набору даних food101\n",
        "#### Індекси класів визначити індивідуально за залежностями: i1=0,i2=30,i3=60 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком групи. "
      ],
      "metadata": {
        "id": "7gpltfxK0sJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4x3QhBju0GqN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import os\n",
        "import zipfile\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"101_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6nwPBdV14VD",
        "outputId": "d53878f0-d630-471d-f98e-7f6a7a59c142"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-03 09:13:46--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.33.208, 172.253.62.128, 172.253.115.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.33.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   114MB/s    in 14s     \n",
            "\n",
            "2022-06-03 09:14:00 (115 MB/s) - ‘101_food_classes_10_percent.zip’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls 101_food_classes_10_percent/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ7SVlZx2QS2",
        "outputId": "89726c99-1096-4368-bb6c-cfe4a8b8cb28"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple_pie\t    eggs_benedict\t     onion_rings\n",
            "baby_back_ribs\t    escargots\t\t     oysters\n",
            "baklava\t\t    falafel\t\t     pad_thai\n",
            "beef_carpaccio\t    filet_mignon\t     paella\n",
            "beef_tartare\t    fish_and_chips\t     pancakes\n",
            "beet_salad\t    foie_gras\t\t     panna_cotta\n",
            "beignets\t    french_fries\t     peking_duck\n",
            "bibimbap\t    french_onion_soup\t     pho\n",
            "bread_pudding\t    french_toast\t     pizza\n",
            "breakfast_burrito   fried_calamari\t     pork_chop\n",
            "bruschetta\t    fried_rice\t\t     poutine\n",
            "caesar_salad\t    frozen_yogurt\t     prime_rib\n",
            "cannoli\t\t    garlic_bread\t     pulled_pork_sandwich\n",
            "caprese_salad\t    gnocchi\t\t     ramen\n",
            "carrot_cake\t    greek_salad\t\t     ravioli\n",
            "ceviche\t\t    grilled_cheese_sandwich  red_velvet_cake\n",
            "cheesecake\t    grilled_salmon\t     risotto\n",
            "cheese_plate\t    guacamole\t\t     samosa\n",
            "chicken_curry\t    gyoza\t\t     sashimi\n",
            "chicken_quesadilla  hamburger\t\t     scallops\n",
            "chicken_wings\t    hot_and_sour_soup\t     seaweed_salad\n",
            "chocolate_cake\t    hot_dog\t\t     shrimp_and_grits\n",
            "chocolate_mousse    huevos_rancheros\t     spaghetti_bolognese\n",
            "churros\t\t    hummus\t\t     spaghetti_carbonara\n",
            "clam_chowder\t    ice_cream\t\t     spring_rolls\n",
            "club_sandwich\t    lasagna\t\t     steak\n",
            "crab_cakes\t    lobster_bisque\t     strawberry_shortcake\n",
            "creme_brulee\t    lobster_roll_sandwich    sushi\n",
            "croque_madame\t    macaroni_and_cheese      tacos\n",
            "cup_cakes\t    macarons\t\t     takoyaki\n",
            "deviled_eggs\t    miso_soup\t\t     tiramisu\n",
            "donuts\t\t    mussels\t\t     tuna_tartare\n",
            "dumplings\t    nachos\t\t     waffles\n",
            "edamame\t\t    omelette\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "PpKk-3ct2SQP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(train_dir)\n",
        "all_class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "\n",
        "indexes = [0, 30, 60]\n",
        "\n",
        "class_names = np.array([])\n",
        "\n",
        "for i, name in enumerate(all_class_names):\n",
        "  if i in indexes:\n",
        "    print(i, name)\n",
        "    class_names = np.append(class_names, name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSdesGiN2X_d",
        "outputId": "f3b5c0bc-8fb7-43d5-e467-4ce69dc344bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 apple_pie\n",
            "30 deviled_eggs\n",
            "60 lobster_bisque\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir beeftartare_eggsbenedict_misosoup\n",
        "\n",
        "!mkdir beeftartare_eggsbenedict_misosoup/train\n",
        "!mkdir beeftartare_eggsbenedict_misosoup/test"
      ],
      "metadata": {
        "id": "oBhuBJ3S2seO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sources = [\n",
        "  'beef_tartare',\n",
        "  'eggs_benedict',\n",
        "  'miso_soup'\n",
        "]\n",
        "\n",
        "for source in sources:\n",
        "  source_dir = train_dir + source\n",
        "  destination_dir = 'beeftartare_eggsbenedict_misosoup/train/' + source\n",
        "  shutil.copytree(source_dir, destination_dir)\n",
        "\n",
        "for source in sources:\n",
        "  source_dir = test_dir + source\n",
        "  destination_dir = 'beeftartare_eggsbenedict_misosoup/test/' + source\n",
        "  shutil.copytree(source_dir, destination_dir)"
      ],
      "metadata": {
        "id": "GpMLA3AI2v_N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"beeftartare_eggsbenedict_misosoup/train/\"\n",
        "test_dir = \"beeftartare_eggsbenedict_misosoup/test/\""
      ],
      "metadata": {
        "id": "-V9L8nAe25Zs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf0nQZJf28MQ",
        "outputId": "7549ab65-ae1f-4374-f057-effa8e5efee9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['beef_tartare' 'eggs_benedict' 'miso_soup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode='categorical')\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iazKpq0v3AGy",
        "outputId": "164c1c50-eb81-431c-8f03-cc034ac5e77f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n",
            "Found 225 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20, \n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(test_dir,\n",
        "                                                                  target_size=(224, 224),\n",
        "                                                                  batch_size=32,\n",
        "                                                                  class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPhUFL-83EWQ",
        "outputId": "d54eb2f9-d13c-4c9c-96b4-eaf03eaf8453"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Conv2D(60, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "result_cnn_model = cnn_model.fit(train_data_augmented,\n",
        "                          epochs=50,\n",
        "                          steps_per_epoch=len(train_data_augmented),\n",
        "                          validation_data=test_data,\n",
        "                          validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PelUGgB-3H0J",
        "outputId": "de01e909-3b8e-43f1-fd4c-58a57606e951"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 161s 7s/step - loss: 1.3548 - accuracy: 0.3373 - val_loss: 1.0488 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 161s 7s/step - loss: 1.0686 - accuracy: 0.3947 - val_loss: 1.0477 - val_accuracy: 0.5067\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 154s 6s/step - loss: 1.0259 - accuracy: 0.4533 - val_loss: 0.8939 - val_accuracy: 0.5378\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.9346 - accuracy: 0.5173 - val_loss: 0.9215 - val_accuracy: 0.5867\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 154s 6s/step - loss: 1.0082 - accuracy: 0.4787 - val_loss: 0.8901 - val_accuracy: 0.5289\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.9143 - accuracy: 0.5147 - val_loss: 0.8389 - val_accuracy: 0.6178\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 156s 6s/step - loss: 0.8954 - accuracy: 0.5693 - val_loss: 0.8005 - val_accuracy: 0.6622\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 154s 6s/step - loss: 0.8889 - accuracy: 0.5707 - val_loss: 0.8777 - val_accuracy: 0.6222\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.8479 - accuracy: 0.6067 - val_loss: 0.7792 - val_accuracy: 0.6667\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 157s 7s/step - loss: 0.8766 - accuracy: 0.5813 - val_loss: 0.8219 - val_accuracy: 0.6444\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.8144 - accuracy: 0.6280 - val_loss: 0.8266 - val_accuracy: 0.6356\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 154s 6s/step - loss: 0.8414 - accuracy: 0.6160 - val_loss: 0.7836 - val_accuracy: 0.6444\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.7759 - accuracy: 0.6413 - val_loss: 0.8392 - val_accuracy: 0.6622\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 154s 7s/step - loss: 0.7830 - accuracy: 0.6360 - val_loss: 0.8069 - val_accuracy: 0.6756\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.7369 - accuracy: 0.6813 - val_loss: 0.7375 - val_accuracy: 0.6844\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 153s 7s/step - loss: 0.8022 - accuracy: 0.6547 - val_loss: 0.8021 - val_accuracy: 0.6800\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.8016 - accuracy: 0.6440 - val_loss: 0.8285 - val_accuracy: 0.6444\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 154s 6s/step - loss: 0.7558 - accuracy: 0.6587 - val_loss: 0.8153 - val_accuracy: 0.6889\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.7572 - accuracy: 0.6693 - val_loss: 0.9416 - val_accuracy: 0.6444\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7786 - accuracy: 0.6453 - val_loss: 0.7548 - val_accuracy: 0.7200\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7314 - accuracy: 0.6800 - val_loss: 0.8201 - val_accuracy: 0.6578\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7335 - accuracy: 0.6747 - val_loss: 0.8266 - val_accuracy: 0.6533\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.7467 - accuracy: 0.6507 - val_loss: 0.7284 - val_accuracy: 0.6933\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7297 - accuracy: 0.6907 - val_loss: 0.7688 - val_accuracy: 0.6844\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7532 - accuracy: 0.6520 - val_loss: 0.8336 - val_accuracy: 0.6489\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 155s 6s/step - loss: 0.7467 - accuracy: 0.6680 - val_loss: 0.7313 - val_accuracy: 0.6844\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6996 - accuracy: 0.6933 - val_loss: 0.7504 - val_accuracy: 0.6933\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.7752 - accuracy: 0.6467 - val_loss: 0.8379 - val_accuracy: 0.6356\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.7049 - accuracy: 0.6933 - val_loss: 0.7937 - val_accuracy: 0.6978\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 150s 6s/step - loss: 0.6796 - accuracy: 0.6973 - val_loss: 0.7528 - val_accuracy: 0.7022\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6936 - accuracy: 0.6853 - val_loss: 0.8903 - val_accuracy: 0.6711\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.7195 - accuracy: 0.6613 - val_loss: 0.8455 - val_accuracy: 0.6756\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 151s 6s/step - loss: 0.6667 - accuracy: 0.7147 - val_loss: 0.7477 - val_accuracy: 0.7067\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.6750 - accuracy: 0.7053 - val_loss: 0.7336 - val_accuracy: 0.7111\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.6555 - accuracy: 0.7133 - val_loss: 0.8986 - val_accuracy: 0.6756\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 151s 6s/step - loss: 0.6992 - accuracy: 0.6840 - val_loss: 0.7926 - val_accuracy: 0.6756\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.7461 - accuracy: 0.6573 - val_loss: 0.7732 - val_accuracy: 0.7067\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6776 - accuracy: 0.7147 - val_loss: 0.7919 - val_accuracy: 0.6978\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6420 - accuracy: 0.7067 - val_loss: 0.9398 - val_accuracy: 0.6622\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 151s 6s/step - loss: 0.6978 - accuracy: 0.6987 - val_loss: 0.7550 - val_accuracy: 0.7156\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6358 - accuracy: 0.7160 - val_loss: 0.7236 - val_accuracy: 0.7022\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 150s 6s/step - loss: 0.6249 - accuracy: 0.7267 - val_loss: 0.6729 - val_accuracy: 0.7244\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 153s 6s/step - loss: 0.6086 - accuracy: 0.7120 - val_loss: 0.6212 - val_accuracy: 0.7200\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 151s 6s/step - loss: 0.6368 - accuracy: 0.7227 - val_loss: 0.8277 - val_accuracy: 0.6800\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 150s 6s/step - loss: 0.6452 - accuracy: 0.7080 - val_loss: 0.7557 - val_accuracy: 0.6800\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.6123 - accuracy: 0.7293 - val_loss: 0.6728 - val_accuracy: 0.7378\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.5945 - accuracy: 0.7307 - val_loss: 0.7370 - val_accuracy: 0.7378\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 150s 6s/step - loss: 0.5863 - accuracy: 0.7573 - val_loss: 0.7292 - val_accuracy: 0.7378\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 151s 6s/step - loss: 0.5754 - accuracy: 0.7413 - val_loss: 0.8147 - val_accuracy: 0.7244\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 152s 6s/step - loss: 0.5572 - accuracy: 0.7573 - val_loss: 0.7544 - val_accuracy: 0.7556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Висновок\n",
        "#### Під час даної лабораторної роботи я розібрала багатокласову класифікацію за допомогою нейромережі Convolutional Neural Networks. А саме, створила нейромережу для розвʼязання задачі класифікації зображень їжі."
      ],
      "metadata": {
        "id": "rQAVk7q_3jdU"
      }
    }
  ]
}